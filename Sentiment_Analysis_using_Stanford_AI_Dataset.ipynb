{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis using Stanford AI Dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/3ZadeSSG/Minor-Project-Sentiment-Analysis/blob/master/Sentiment_Analysis_using_Stanford_AI_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "k3kr18m0qK7s",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files,drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z523O_B3qQR0",
        "outputId": "f8636b2f-17b7-47f3-9585-d9cf19e80a0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Hgkd5h8BG3N-",
        "outputId": "ccf55816-d91a-400e-8c41-ff530dcce507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Get the generated helper functions to process the data and create proper datasets to be converted into tensors\n",
        "!wget -c https://raw.githubusercontent.com/3ZadeSSG/Minor-Project-Sentiment-Analysis/master/myModelHelper.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-07 14:21:31--  https://raw.githubusercontent.com/3ZadeSSG/Minor-Project-Sentiment-Analysis/master/myModelHelper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2790 (2.7K) [text/plain]\n",
            "Saving to: ‘myModelHelper.py’\n",
            "\n",
            "\rmyModelHelper.py      0%[                    ]       0  --.-KB/s               \rmyModelHelper.py    100%[===================>]   2.72K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-04-07 14:21:31 (55.4 MB/s) - ‘myModelHelper.py’ saved [2790/2790]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "85fw4k4rHawu",
        "outputId": "5ebf52ef-df51-43ca-92d2-07b3a1858104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Get data directly from url\n",
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-07 14:21:35--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  19.2MB/s    in 7.0s    \n",
            "\n",
            "2019-04-07 14:21:42 (11.5 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Fzb4-4g-Hhk1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract data\n",
        "!tar -xvzf aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z48JUwW7GYeB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "from myModelHelper import *\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "A0zDAkRQGp-O",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SentimentNetwork(nn.Module):\n",
        "  def __init__(self,vocabulary_size,output_size,embedding_dimension,hidden_dimension,number_of_layers,dropout_probability=0.5):\n",
        "    super(SentimentNetwork,self).__init__()\n",
        "    # class data for weight matrix size\n",
        "    self.output_size=output_size\n",
        "    self.number_of_layers=number_of_layers\n",
        "    self.hidden_dimension=hidden_dimension\n",
        "    # create the embedding layer to reduce dimension \n",
        "    # and LSTM layer containing LSTM cells \n",
        "    self.embedding=nn.Embedding(vocabulary_size,embedding_dimension)\n",
        "    self.lstm=nn.LSTM(embedding_dimension,hidden_dimension,number_of_layers,dropout=dropout_probability,batch_first=True)\n",
        "    \n",
        "    # Create dropout layer as a regularization method to reduct overfitting\n",
        "    # this will disable some units in forward pass, thus preventing \n",
        "    # a particular set of node's weights getting updated while others remain unused\n",
        "    self.dropout=nn.Dropout(dropout_probability)\n",
        "    \n",
        "    # attach final  linear layer with sigmoid function\n",
        "    self.finalLayer=nn.Linear(hidden_dimension,output_size)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "   \n",
        "  def forward(self,x,hidden):\n",
        "    batch_size=x.size(0)\n",
        "    embedding_output=self.embedding(x)\n",
        "    \n",
        "    #lstm will take the current input and hidden state as input \n",
        "    # and will generate the output to be feed at the linear layer\n",
        "    lstm_output,hidden=self.lstm(embedding_output,hidden)\n",
        "    lstm_output=lstm_output.contiguous().view(-1,self.hidden_dimension)\n",
        "    \n",
        "    output=self.dropout(lstm_output)\n",
        "    output=self.finalLayer(output)\n",
        "    \n",
        "    #call the sigmoid function on current output of final layer\n",
        "    sigmoid_output=self.sigmoid(output)\n",
        "    sigmoid_output=sigmoid_output.view(batch_size,-1)\n",
        "    #only get the last position output for all batches\n",
        "    sigmoid_output=sigmoid_output[:,-1]\n",
        "    \n",
        "    #current sigmoid output and a hidden state to be fed as input for next pass\n",
        "    # into the LSTM cells, so that they will be dependent on the previous state\n",
        "    return sigmoid_output,hidden\n",
        "  \n",
        "  def initialize_hidden_state(self,batch_size):\n",
        "    # At first the hidden state will not hold any information, hence we need to\n",
        "    # initialize them with zeros\n",
        "    # Number_of_Layers x Batch_Size x Hidden_Dimension\n",
        "    weight=next(self.parameters()).data\n",
        "    if(torch.cuda.is_available()):\n",
        "      # if GPU is available then initialize the weights parallely\n",
        "      hidden=(weight.new(self.number_of_layers,batch_size,self.hidden_dimension).zero_().cuda(),weight.new(self.number_of_layers,batch_size,self.hidden_dimension).zero_().cuda())\n",
        "    else:\n",
        "      hidden=(weight.new(self.number_of_layers,batch_size,self.hidden_dimension).zero_(),weight.new(self.number_of_layers,batch_size,self.hidden_dimension).zero_())\n",
        "      \n",
        "    return hidden\n",
        "      \n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "136bBBgPVpKm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.optim import Optimizer\n",
        "import  math\n",
        "class AdamOptimizerAlgorithm(Optimizer):\n",
        "  \n",
        "    \n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8):\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps)\n",
        "        super(AdamOptimizerAlgorithm, self).__init__(params, defaults)\n",
        "\n",
        "    def step(self):\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                state = self.state[p]\n",
        "\n",
        "                # State initialization in case of initial state\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "                    \n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                \n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                state['step'] += 1\n",
        "\n",
        "                #following is just a formula implementaion of the algorithm\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                \n",
        "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "\n",
        "                b_1 = 1 - beta1 ** state['step']\n",
        "                b_2 = 1 - beta2 ** state['step']\n",
        "                step_size = group['lr'] * math.sqrt(b_2) / b_1\n",
        "                \n",
        "                p.data.addcdiv_(-step_size, exp_avg, denom)  # -step_size*(exp_avg/denom) operation done in single step\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "a41iJq2QGqAP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def buildNetwork():\n",
        "  #Our model parameters\n",
        "  vocabulary_size=len(vocab_to_int)+1\n",
        "  output_size=1\n",
        "  embedding_dimension=200\n",
        "  hidden_dimension=256\n",
        "  number_of_layers=2\n",
        "  \n",
        "  model=SentimentNetwork(vocabulary_size,output_size,embedding_dimension,hidden_dimension,number_of_layers)\n",
        "  \n",
        "  # Alpha value\n",
        "  learning_rate=0.003\n",
        "  \n",
        "  # Error calculating formula (Mean Square Error)\n",
        "  criterion = nn.MSELoss() \n",
        " \n",
        "  #Adam optimization technique for first-order gradient-based optimization\n",
        "  optimizer=AdamOptimizerAlgorithm(model.parameters(),lr=learning_rate)\n",
        "  \n",
        "  \n",
        "  return model,criterion,optimizer\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9uf1QFQPT5Ra",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainNetwork(model,epochs,print_interval,criterion,optimizer):\n",
        "  Iteration=[]\n",
        "  Training_Loss=[]\n",
        "  Validation_Loss=[]\n",
        "  \n",
        "  minimum_validation_loss=np.Inf\n",
        "  \n",
        "  # Since each epoch goes over all data and\n",
        "  # each iteration goes over the data in batches\n",
        "  count=0\n",
        "  \n",
        "  # move model to GPU \n",
        "  model.cuda()\n",
        "  \n",
        "  #put the model into training model so that the gradients will \n",
        "  # be calculated\n",
        "  model.train()\n",
        "  for i in range(epochs):\n",
        "    # for each epoch perform a forward pass for all batches\n",
        "    # and around epoch 4 reduce the learning rate\n",
        "    hidden_state=model.initialize_hidden_state(batch_size)\n",
        "    \n",
        "    if(i==3):\n",
        "      print(\"\\n\\nReducing the learning rate!\\n\" )\n",
        "      #optimizer=torch.optim.Adam(model.parameters(),lr=0.0002)\n",
        "      optimizer=AdamOptimizerAlgorithm(model.parameters(),lr=0.0002)\n",
        "    \n",
        "    for inputs,labels in train_loader:\n",
        "      count+=1\n",
        "      # move the data to GPU\n",
        "      inputs,labels=inputs.cuda(),labels.cuda()\n",
        "      \n",
        "      #create new variable for hidden state otherwise it will include all\n",
        "      #pervious states\n",
        "      hidden_state=tuple([element.data for element in hidden_state])\n",
        "      \n",
        "      model.zero_grad()\n",
        "      \n",
        "      inputs=inputs.long()\n",
        "      output,hidden_state=model(inputs,hidden_state)\n",
        "      \n",
        "      #calculate the loss to backpropagare to model\n",
        "      #loss=torch.sqrt(criterion(output.squeeze(),labels.float()))\n",
        "      loss=criterion(output.squeeze(),labels.float())\n",
        "      loss.backward()\n",
        "\n",
        "      \n",
        "      #nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
        "      optimizer.step()\n",
        "      \n",
        "      if(count%print_interval==0):\n",
        "        temp_hidden=model.initialize_hidden_state(batch_size)\n",
        "        temp_losses=[]\n",
        "        model.eval()\n",
        "        for inputs,labels in validation_loader:\n",
        "          temp_hidden=tuple([element.data for element in temp_hidden])\n",
        "          inputs,labels=inputs.cuda().long(),labels.cuda()\n",
        "          \n",
        "          output,temp_hidden=model(inputs,temp_hidden)\n",
        "          validation_loss=criterion(output.squeeze(),labels.float())\n",
        "          temp_losses.append(validation_loss.item())\n",
        "        \n",
        "        model.train()\n",
        "        print(\"Epoch: {}\\tIteration: {}\\tTraining Loss: {:.7f}\\tValidation Loss: {:.7f}\".format(\n",
        "        (i+1),count,loss.item(),np.mean(temp_losses)))\n",
        "        Iteration.append(count)\n",
        "        Training_Loss.append(loss.item())\n",
        "        Validation_Loss.append(np.mean(temp_losses))\n",
        "        \n",
        "        if np.mean(temp_losses)<minimum_validation_loss:\n",
        "            save_checkpoint(model,\"checkpoint.pth\")\n",
        "            minimum_validation_loss=np.mean(temp_losses)\n",
        "            print(\"Validation loss decreased  hence saving checkpoint successfully\")\n",
        "                  \n",
        "         \n",
        "\n",
        "\n",
        "  plt.plot(Iteration,Training_Loss)\n",
        "  plt.plot(Iteration,Validation_Loss)\n",
        "  plt.xlabel('Iteration')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.ylim(0.0,1.0)\n",
        "  plt.legend(['Training Loss','Validation Loss'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VMCv-pJkTL58",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model,fileLocation):\n",
        "  # save the current state_dict which contains all the weights of the network\n",
        "  torch.save(model.state_dict(),fileLocation)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DqJmKTYwTZjC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_Checkpoint(fileLocation):\n",
        "  #model=buildNetwork()\n",
        "  model,criterion,optimizer=buildNetwork()\n",
        "  model.load_state_dict(torch.load(fileLocation))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UB0x9fla3AmK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def checkAccuracy(model,test_loader):\n",
        "  #move model to GPU\n",
        "  model.cuda()\n",
        "  \n",
        "  test_losses=[]\n",
        "  correct_prediction=0\n",
        "  \n",
        "  #set initial state to zero\n",
        "  hidden_state=model.initialize_hidden_state(batch_size)\n",
        "  \n",
        "  # set the model into evaluation mode, so that we don't need to calculate\n",
        "  # the gradients\n",
        "  model.eval()\n",
        "  \n",
        "  for inputs,labels in test_loader:\n",
        "    \n",
        "    # move the data and labels into GPU\n",
        "    inputs,labels=inputs.cuda().long(),labels.cuda().long()\n",
        "    \n",
        "    output,hidden_state=model(inputs,hidden_state)\n",
        "    # labels are initially long or int, we need to conver them into float\n",
        "    # so that loss cab be calculated in float value\n",
        "    test_loss=criterion(output.squeeze(),labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "    # get the prediction either 1 or 0\n",
        "    prediction=torch.round(output.squeeze())\n",
        "    \n",
        "    correct_tensor=prediction.eq(labels.float().view_as(prediction))   \n",
        "    correct=np.squeeze(correct_tensor.cpu().numpy())\n",
        "    correct_prediction+=np.sum(correct)\n",
        "  \n",
        "  #print(np.mean(test_losses))\n",
        "  print(\"Accuracy: {:.4f}\".format(correct_prediction/len(test_loader.dataset)))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-DQjhHHKdjS-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenize_sentence(sentence):\n",
        "  sentence=sentence.lower()\n",
        "  \n",
        "  #remove punctuation\n",
        "  sentence=''.join([letter for letter in sentence if letter not in punctuation])\n",
        "  \n",
        "  test_words=sentence.split()\n",
        "  tokens=[]\n",
        "  sample=[]\n",
        "  for word in test_words:\n",
        "      if word in vocab_to_int:\n",
        "          sample.append(word)\n",
        "  tokens.append([vocab_to_int[word] for word in sample])\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tFAQve__djXX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(model,sentence,sequence_length=200):\n",
        "  model.cuda()\n",
        "  model.eval()\n",
        "  \n",
        "  test_ints=tokenize_sentence(sentence)\n",
        "  features=featuresPadding(test_ints,sequence_length)\n",
        "  feature_tensor=torch.from_numpy(features)\n",
        "  batch_size=feature_tensor.size(0)\n",
        "  \n",
        "  hidden_state=model.initialize_hidden_state(batch_size)\n",
        "  feature_tensor=feature_tensor.cuda().long()\n",
        "  output,hidden_state=model(feature_tensor,hidden_state)\n",
        "  prediction=torch.round(output.squeeze())\n",
        "  if(prediction.item()==0):\n",
        "    print(\"{:.4f}\\t Negative sentence!\".format(output.item()))\n",
        "  else:\n",
        "    print(\"{:.4f}\\t Positive sentence!\".format(output.item()))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KZTaWPd2Gp1X",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "negativeDataPath=\"aclImdb/train/neg/\"\n",
        "positiveDataPath=\"aclImdb/train/pos/\"\n",
        "fileLocation='/content/drive/My Drive/SEM-III Project/SentimentAnalysisCheckpoint.pth'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "D1EoH7-hGp33",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reviews,labels=createData(positiveDataPath,negativeDataPath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0yhFfFOzueUL",
        "outputId": "ec5a72f7-072b-4dd3-d481-b7cd9d8a1d82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(reviews),len(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33151741, 225000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DPVaPTNZIbSu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seq_length=200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Pjak8byWGp5-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features,encoded_labels,vocab_to_int=getFeaturesLabels(reviews,labels,seq_length)\n",
        "\n",
        "train_x,train_y,test_x,test_y,val_x,val_y=createTrainTestValidateData(0.8,features,encoded_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rP1Y1i4FGp8A",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "validation_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "batch_size=100\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "validation_loader = DataLoader(validation_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vxzyRGHMumss",
        "outputId": "cd6f934d-5407-4701-bc30-bba62a912efe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Training: \\t\",np.shape(train_x))\n",
        "print(\"Validation: \\t\",np.shape(val_x))\n",
        "print(\"Test: \\t\\t\",np.shape(test_x))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: \t (20000, 200)\n",
            "Validation: \t (2500, 200)\n",
            "Test: \t\t (2500, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UbEv55TFT5UK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model,criterion,optimizer=buildNetwork()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "V3kFoVxm3AeW",
        "outputId": "aef4be4f-70dc-4e39-9c6b-886e91e5bff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentNetwork(\n",
              "  (embedding): Embedding(121365, 200)\n",
              "  (lstm): LSTM(200, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (dropout): Dropout(p=0.5)\n",
              "  (finalLayer): Linear(in_features=256, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZS9jGePv3Ag1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_interval = 100\n",
        "epochs = 16 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "enEkdI103Ajl",
        "outputId": "7849834d-db14-4058-d4c0-768d01289818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1113
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time=time.time()\n",
        "trainNetwork(model,epochs,print_interval,criterion,optimizer)\n",
        "print(\"\\n\\nTraining Time: {} minutes\".format((time.time()-start_time)/60))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\tIteration: 100\tTraining Loss: 0.2356652\tValidation Loss: 0.2396529\n",
            "Validation loss decreased  hence saving checkpoint successfully\n",
            "Epoch: 1\tIteration: 200\tTraining Loss: 0.2294783\tValidation Loss: 0.1879363\n",
            "Validation loss decreased  hence saving checkpoint successfully\n",
            "Epoch: 2\tIteration: 300\tTraining Loss: 0.1221827\tValidation Loss: 0.2087412\n",
            "Epoch: 2\tIteration: 400\tTraining Loss: 0.0933442\tValidation Loss: 0.1456503\n",
            "Validation loss decreased  hence saving checkpoint successfully\n",
            "Epoch: 3\tIteration: 500\tTraining Loss: 0.1012263\tValidation Loss: 0.1369326\n",
            "Validation loss decreased  hence saving checkpoint successfully\n",
            "Epoch: 3\tIteration: 600\tTraining Loss: 0.1288696\tValidation Loss: 0.1238711\n",
            "Validation loss decreased  hence saving checkpoint successfully\n",
            "\n",
            "\n",
            "Reducing the learning rate!\n",
            "\n",
            "Epoch: 4\tIteration: 700\tTraining Loss: 0.0352292\tValidation Loss: 0.1298226\n",
            "Epoch: 4\tIteration: 800\tTraining Loss: 0.0395323\tValidation Loss: 0.1287776\n",
            "Epoch: 5\tIteration: 900\tTraining Loss: 0.0404341\tValidation Loss: 0.1325075\n",
            "Epoch: 5\tIteration: 1000\tTraining Loss: 0.0167642\tValidation Loss: 0.1333889\n",
            "Epoch: 6\tIteration: 1100\tTraining Loss: 0.0527032\tValidation Loss: 0.1342535\n",
            "Epoch: 6\tIteration: 1200\tTraining Loss: 0.0265984\tValidation Loss: 0.1319116\n",
            "Epoch: 7\tIteration: 1300\tTraining Loss: 0.0052540\tValidation Loss: 0.1332736\n",
            "Epoch: 7\tIteration: 1400\tTraining Loss: 0.0150551\tValidation Loss: 0.1333146\n",
            "Epoch: 8\tIteration: 1500\tTraining Loss: 0.0218665\tValidation Loss: 0.1352145\n",
            "Epoch: 8\tIteration: 1600\tTraining Loss: 0.0499543\tValidation Loss: 0.1328574\n",
            "Epoch: 9\tIteration: 1700\tTraining Loss: 0.0185096\tValidation Loss: 0.1360238\n",
            "Epoch: 9\tIteration: 1800\tTraining Loss: 0.0368802\tValidation Loss: 0.1415351\n",
            "Epoch: 10\tIteration: 1900\tTraining Loss: 0.0284689\tValidation Loss: 0.1379222\n",
            "Epoch: 10\tIteration: 2000\tTraining Loss: 0.0310027\tValidation Loss: 0.1412146\n",
            "Epoch: 11\tIteration: 2100\tTraining Loss: 0.0205711\tValidation Loss: 0.1418187\n",
            "Epoch: 11\tIteration: 2200\tTraining Loss: 0.0103225\tValidation Loss: 0.1413574\n",
            "Epoch: 12\tIteration: 2300\tTraining Loss: 0.0390445\tValidation Loss: 0.1433604\n",
            "Epoch: 12\tIteration: 2400\tTraining Loss: 0.0052759\tValidation Loss: 0.1412638\n",
            "Epoch: 13\tIteration: 2500\tTraining Loss: 0.0010678\tValidation Loss: 0.1416073\n",
            "Epoch: 13\tIteration: 2600\tTraining Loss: 0.0106288\tValidation Loss: 0.1443913\n",
            "Epoch: 14\tIteration: 2700\tTraining Loss: 0.0103763\tValidation Loss: 0.1472553\n",
            "Epoch: 14\tIteration: 2800\tTraining Loss: 0.0004787\tValidation Loss: 0.1465307\n",
            "Epoch: 15\tIteration: 2900\tTraining Loss: 0.0326908\tValidation Loss: 0.1430379\n",
            "Epoch: 15\tIteration: 3000\tTraining Loss: 0.0211190\tValidation Loss: 0.1475482\n",
            "Epoch: 16\tIteration: 3100\tTraining Loss: 0.0200020\tValidation Loss: 0.1501372\n",
            "Epoch: 16\tIteration: 3200\tTraining Loss: 0.0232684\tValidation Loss: 0.1474636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFcCAYAAADh1zYWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKiPeAFAZ8QaAynwBXWSNoJAWsRAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Training Time: 8.966030804316203 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "XoGaFKm9uI4h"
      },
      "cell_type": "markdown",
      "source": [
        "### Checking the overfitted model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eOdZ7QRfdjVt",
        "outputId": "1e6048a3-2f29-49d6-ed17-2223a73ebc6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "checkAccuracy(model,test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eUNkUWNlT5W5",
        "outputId": "4339b07f-344a-4d01-d2d9-b061dfa71840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "checkAccuracy(model,train_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GoKlgqs5u-7P",
        "outputId": "e7c27c23-a430-452b-de79-92179af16a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "checkAccuracy(model,validation_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8E5CtnYwuNMW"
      },
      "cell_type": "markdown",
      "source": [
        "### Checking the model which was saved as temporary checkpoint after validation loss decreased"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "T-iaBml6aJJX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2=load_Checkpoint(\"checkpoint.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "b7gbNbK6bIa0",
        "outputId": "b9fd59f0-7e0e-4056-b7af-3f9a35d4b04a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "checkAccuracy(model2.cuda(),test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KfsrBvaDdVwH",
        "outputId": "3067df57-834a-4dd9-fb6c-29e308472d20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "checkAccuracy(model2.cuda(),train_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9410\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VU-JgA8ddZc8",
        "outputId": "5f43bec0-f0df-4563-d1e6-7570162b5465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "checkAccuracy(model2.cuda(),validation_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "AN1hxjVruXoO"
      },
      "cell_type": "markdown",
      "source": [
        "### Saving the perfectly trained model to google drive"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5k9494IFbLgP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# saving the trained model to google drive\n",
        "save_checkpoint(model2,fileLocation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cnMCx9gat3i1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model3=load_Checkpoint(fileLocation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uxfi086st9q_",
        "outputId": "784ba4f9-465b-4cf5-d284-f2dd58d09658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "checkAccuracy(model3.cuda(),test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wmifuQ7Fu--X",
        "outputId": "27eaf42e-5cf3-406e-e9a8-22468286dab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "predict(model2, 'Kamikaze album by eminem has to be one of the best albums that came out last year, other than few tracks, evey track was lit', seq_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9501\t Positive sentence!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "shAzjr2Lu_Br",
        "outputId": "6abec76c-502a-4b07-bf49-c92d5938e9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "sentence = 'Drake published 3 trash albums this year,each song gave pain at different part of my brain  he deserves rotten tomatoes'\n",
        "predict(model2,sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4549\t Negative sentence!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hFWDi3GWaWld",
        "colab_type": "code",
        "outputId": "ef2d54c3-d9f0-4b06-fedc-89118134f72c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "predict(model2, 'this was the worst movie i have ever seen', seq_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0673\t Negative sentence!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FQgSeGtkVbFu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#saving the created dictonary for future use\n",
        "np.save(\"vocab_to_int.npy\", vocab_to_int)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}